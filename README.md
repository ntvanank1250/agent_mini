# ğŸ¤– AI Agent Telegram Bot - Cháº¡y Ollama Local

Há»‡ thá»‘ng AI Agent cÃ¡ nhÃ¢n hoÃ n toÃ n **cháº¡y cá»¥c bá»™** (Local) trÃªn Linux 8GB RAM, tÃ­ch há»£p Telegram Bot, Ollama AI Engine qwen2.5:7b, vÃ  quáº£n lÃ½ ngÆ°á»i dÃ¹ng whitelist.

**NgÃ´n ngá»¯:** Tiáº¿ng Viá»‡t tá»‘i Æ°u | **Model:** qwen2.5:7b (4.7GB) | **Thread:** 8 cores | **DB:** SQLite

## ğŸ“‹ TÃ­nh NÄƒng ChÃ­nh

### ğŸ¤– AI & Chat
- âœ… **Ollama qwen2.5:7b** - Model tá»‘i Æ°u tiáº¿ng Viá»‡t, cháº¡y trÃªn CPU
- âœ… **Telegram Interface** - TÆ°Æ¡ng tÃ¡c trá»±c tiáº¿p qua Telegram
- âœ… **Conversation Memory** - LÆ°u lá»‹ch sá»­ 20 messages gáº§n nháº¥t
- âœ… **Vietnamese Enforced** - System prompt báº¯t buá»™c tráº£ lá»i tiáº¿ng Viá»‡t
- âœ… **File Analysis** - Táº£i lÃªn file .txt Ä‘á»ƒ phÃ¢n tÃ­ch ná»™i dung

### ğŸ” Quáº£n LÃ½ NgÆ°á»i DÃ¹ng
- âœ… **Whitelist System** - Admin thÃªm/xÃ³a ngÆ°á»i dÃ¹ng cÃ³ quyá»n
- âœ… **/add <chat_id>** - ThÃªm ngÆ°á»i dÃ¹ng vÃ o danh sÃ¡ch tráº¯ng
- âœ… **/remove <chat_id>** - XÃ³a ngÆ°á»i dÃ¹ng khá»i danh sÃ¡ch
- âœ… **/whitelist** - Xem danh sÃ¡ch ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c phÃ©p

### âš™ï¸ Há»‡ Thá»‘ng
- âœ… **Queue System** - Xá»­ lÃ½ 1 request AI táº¡i má»™t lÃºc (lock-based)
- âœ… **System Monitor** - Kiá»ƒm tra RAM/CPU real-time (/sys)
- âœ… **Garbage Collection** - Tá»± Ä‘á»™ng giáº£i phÃ³ng bá»™ nhá»›
- âœ… **Optimization** - 8 threads, context 4096, temperature 0.3
- âœ… **Auto-restart** - Quáº£n lÃ½ script (start/stop/status)

## ğŸ› ï¸ YÃªu Cáº§u Há»‡ Thá»‘ng

```
Hardware:
  - CPU: 12 cores (tá»‘i Æ°u), tá»‘i thiá»ƒu 4 cores
  - RAM: 15GB total (11GB Ollama+Python, 4GB swap)
  - Disk: 20GB minimum (4.7GB model + data)
  - OS: Linux (Fedora, Ubuntu, Debian)

ÄÃ£ test trÃªn:
  âœ“ Fedora 41 - 12 cores, 15GB RAM
  âœ“ Intel 8-core CPU
```

## ğŸš€ CÃ i Äáº·t & Cháº¡y

### Option 1: Automatic Setup (Khuyáº¿n nghá»‹)

```bash
cd /home/hieudd/code/agent_mini

# Copy config template
cp .env.example .env

# Chá»‰nh sá»­a .env - thÃªm Telegram bot token
nano .env
# TELEGRAM_API_TOKEN=your_bot_token_here
# ADMIN_CHAT_ID=your_chat_id

# Cháº¡y setup (cÃ i Ollama, Python packages, venv)
chmod +x setup_system.sh
sudo ./setup_system.sh

# Khá»Ÿi Ä‘á»™ng bot
./manage.sh start

# Kiá»ƒm tra tráº¡ng thÃ¡i
./manage.sh status
```

### Option 2: Manual Setup

```bash
# 1. CÃ i Ollama
curl https://ollama.ai/install.sh | sh

# 2. Táº£i model
ollama pull qwen2.5:7b

# 3. Khá»Ÿi Ä‘á»™ng Ollama
ollama serve &

# 4. CÃ i Python packages
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 5. Thiáº¿t láº­p .env
cp .env.example .env
nano .env  # thÃªm TELEGRAM_API_TOKEN

# 6. Cháº¡y bot
source venv/bin/activate
python3 tele_agent.py
```

## ğŸ“± CÃ¡c Lá»‡nh Telegram

### Cho Admin

| Lá»‡nh | MÃ´ Táº£ | VÃ­ Dá»¥ |
|------|-------|-------|
| `/start` | Hiá»ƒn thá»‹ menu chÃ­nh | `/start` |
| `/help` | HÆ°á»›ng dáº«n chi tiáº¿t | `/help` |
| `/sys` | Kiá»ƒm tra RAM/CPU/Queue | `/sys` |
| `/clear` | XÃ³a lá»‹ch sá»­ chat | `/clear` |
| `/add <id> [name]` | ThÃªm user whitelist | `/add 987654321 john` |
| `/remove <id>` | XÃ³a user whitelist | `/remove 987654321` |
| `/whitelist` | Xem danh sÃ¡ch user | `/whitelist` |
| `[text]` | Chat vá»›i AI | `giÃ¡ vÃ ng hÃ´m nay` |
| `[file.txt]` | PhÃ¢n tÃ­ch file | Gá»­i file .txt |

### Cho Whitelisted Users

- `/start` `/help` `/sys` `/clear` - Lá»‡nh thÃ´ng thÆ°á»ng
- Text chat, file upload - Äáº§y Ä‘á»§ tÃ­nh nÄƒng

## ğŸ“Š Cáº¥u TrÃºc Project

```
agent_mini/
â”œâ”€â”€ tele_agent.py              # Bot chÃ­nh (873 dÃ²ng)
â”‚   â”œâ”€ Config class            # Load .env
â”‚   â”œâ”€ ChatDatabase            # SQLite + whitelist table
â”‚   â”œâ”€ RequestQueue            # Lock-based queue
â”‚   â”œâ”€ AIAgent                 # Ollama client
â”‚   â”œâ”€ Handlers                # /start, /add, /remove, /whitelist, etc
â”‚   â””â”€ SystemMonitor           # RAM/CPU check
â”œâ”€â”€ manage.sh                  # Quáº£n lÃ½ bot (start/stop/status/logs)
â”œâ”€â”€ setup_system.sh            # CÃ i Ä‘áº·t tá»± Ä‘á»™ng (360 dÃ²ng)
â”œâ”€â”€ start.sh, stop.sh          # Shortcuts
â”œâ”€â”€ status.sh, logs.sh         # Kiá»ƒm tra tráº¡ng thÃ¡i
â”œâ”€â”€ .env.example               # Config template
â”œâ”€â”€ .env                       # Config thá»±c (git ignored)
â”œâ”€â”€ requirements.txt           # Python packages
â”œâ”€â”€ data/
â”‚   â””â”€ chat_history.db        # SQLite database
â”œâ”€â”€ docker-compose.yml         # Open WebUI (optional)
â””â”€â”€ README.md (this file)

```

## âš™ï¸ Cáº¥u HÃ¬nh (.env)

```bash
# Telegram
TELEGRAM_API_TOKEN=your_bot_token_here
ADMIN_CHAT_ID=your_chat_id_here

# Ollama
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b

# System
MAX_WORKERS=1                  # Chá»‰ 1 request táº¡i má»™t lÃºc
QUEUE_CHECK_INTERVAL=2         # Check queue má»—i 2s
HISTORY_LIMIT=20               # LÆ°u 20 tin nháº¯n
```

## ğŸ”§ Quáº£n LÃ½ Bot

```bash
# Khá»Ÿi Ä‘á»™ng
./manage.sh start

# Dá»«ng
./manage.sh stop

# Kiá»ƒm tra tráº¡ng thÃ¡i
./manage.sh status

# Xem logs real-time
./manage.sh logs-live

# Backup database
./manage.sh db-backup

# Dá»n dáº¹p dá»¯ liá»‡u cÅ© (>30 ngÃ y)
./manage.sh db-cleanup

# Reset bot (xÃ³a cache, khá»Ÿi Ä‘á»™ng láº¡i)
./manage.sh reset
```

## ğŸ“ˆ Performance & Optimization

### Tuned Parameters
```
- Threads: 8 cores (táº­n dá»¥ng CPU multicore)
- Context Window: 4096 tokens
- Temperature: 0.3 (tÄƒng tÃ­nh chÃ­nh xÃ¡c)
- Repeat Penalty: 1.2 (trÃ¡nh láº·p)
- Top-K: 30, Top-P: 0.8 (sampling)
```

### Thá»i Gian Pháº£n Há»“i
- **Láº§n Ä‘áº§u**: ~10-15 giÃ¢y (load model)
- **Láº§n sau**: ~5-8 giÃ¢y (inference on CPU)
- **Whitelist check**: <100ms

### Memory Usage
- **Ollama**: ~4.7GB (model)
- **Python bot**: ~60MB
- **SQLite**: ~5MB
- **Swap**: 4GB (Ä‘Æ°á»£c cáº¥u hÃ¬nh tá»± Ä‘á»™ng)

## ğŸ› Troubleshooting

### Bot khÃ´ng pháº£n há»“i
```bash
# Check náº¿u bot cÃ²n cháº¡y
pgrep -a tele_agent.py

# Xem logs
tail -50 bot_agent.log

# Restart
./manage.sh stop && sleep 2 && ./manage.sh start
```

### Ollama khÃ´ng káº¿t ná»‘i
```bash
# Check Ollama running
pgrep ollama

# Kiá»ƒm tra port 11434
curl http://localhost:11434/api/tags

# Khá»Ÿi Ä‘á»™ng láº¡i
ollama serve &
```

### .env nÃ£o tÃ¬m tháº¥y
```bash
# Copy tá»« template
cp .env.example .env

# ThÃªm token Telegram
TELEGRAM_API_TOKEN=your_token_here
ADMIN_CHAT_ID=your_id_here
```

## ğŸ“š File Documentations

- [INSTALLATION_GUIDE.md](./INSTALLATION_GUIDE.md) - HÆ°á»›ng dáº«n chi tiáº¿t
- [AI_AGENT_INSTRUCTIONS.md](./.github/instructions/AI_AGENT_INSTRUCTIONS.md) - Spec ká»¹ thuáº­t
- [setup_system.sh](./setup_system.sh) - Script setup
- [tele_agent.py](./tele_agent.py) - Source code main

## ğŸ›¡ï¸ Báº£o Máº­t

- âœ… Chá»‰ Admin chÃ­nh + whitelist users cÃ³ quyá»n
- âœ… Má»—i user isolate (riÃªng SQLite history)
- âœ… API token khÃ´ng in logs
- âœ… File táº£i lÃªn Ä‘Æ°á»£c xÃ³a sau khi xá»­ lÃ½

## ğŸ“ License

Personal use - Local AI Bot for Vietnamese users

## ğŸ‘¤ Author

Duy Hieu - Vietnamese AI Agent Project

---

**Last Updated:** 2026-02-27 | **Version:** 1.2-whitelist

## ğŸ“‹ TÃ­nh NÄƒng

- âœ… **Ollama AI Integration**: qwen2.5:7b model (tá»‘i Æ°u tiáº¿ng Viá»‡t)
- âœ… **Telegram Bot**: TÆ°Æ¡ng tÃ¡c qua Telegram Messenger
- âœ… **Web Interface**: Open WebUI giá»‘ng Zerobot/ChatGPT (port 3000)
- âœ… **Conversation Memory**: LÆ°u lá»‹ch sá»­ chat vÃ o SQLite
- âœ… **Queue System**: Xá»© lÃ½ 1 request AI táº¡i má»™t lÃºc (8GB RAM optimized)
- âœ… **File Processing**: PhÃ¢n tÃ­ch file .txt tá»± Ä‘á»™ng
- âœ… **System Monitoring**: Kiá»ƒm tra RAM/CPU real-time
- âœ… **Memory Optimization**: Garbage collection, swap file, caching
- âœ… **Access Control**: Chá»‰ cho phÃ©p 1 admin sá»­ dá»¥ng

## ğŸ› ï¸ YÃªu Cáº§u Há»‡ Thá»‘ng

```
Hardware:
  - CPU: 4 Core (khuyáº¿n nghá»‹)
  - RAM: 8GB (cáº§n 6GB cho Ollama + 2GB cho há»‡ thá»‘ng)
  - Disk: 20GB (cho model + data)
  - Network: Káº¿t ná»‘i internet Ä‘á»ƒ cÃ i Ä‘áº·t

OS:
  - Ubuntu 20.04 LTS hoáº·c cao hÆ¡n
  - Linux based (Debian, CentOS, etc)
```

## ğŸš€ Quick Start

### 1ï¸âƒ£ Clone & Cáº¥u HÃ¬nh

```bash
cd /home/hieudd/code/agent_mini

# Copy file cáº¥u hÃ¬nh
cp .env.example .env

# Chá»‰nh sá»­a .env vá»›i thÃ´ng tin cá»§a báº¡n
nano .env
```

### 2ï¸âƒ£ Cháº¡y Setup Script

```bash
# Cáº¥p quyá»n thá»±c thi
chmod +x setup_system.sh

# Cháº¡y script (cáº§n sudo)
sudo ./setup_system.sh

# This sáº½:
# âœ“ Táº¡o 4GB swap file (RAM optimization)
# âœ“ CÃ i Ollama + Pull qwen2.5:7b model (~5GB, máº¥t 10-15 phÃºt)
# âœ“ CÃ i Docker + Open WebUI image
# âœ“ Táº¡o Python venv + install dependencies
# âœ“ Kiá»ƒm tra toÃ n bá»™ cÃ i Ä‘áº·t
```

### 3ï¸âƒ£ Khá»Ÿi Äá»™ng Ollama

```bash
# CÃ¡ch 1: Sá»­ dá»¥ng systemd (recommended)
sudo systemctl start ollama
sudo systemctl enable ollama  # Tá»± Ä‘á»™ng start khi reboot

# CÃ¡ch 2: Cháº¡y thá»§ cÃ´ng
ollama serve

# Kiá»ƒm tra
ollama list
```

### 4ï¸âƒ£ Khá»Ÿi Äá»™ng Web UI (Optional)

```bash
# Náº¿u Ä‘Ã£ cÃ i Docker
docker run -d -p 3000:8080 --name open-webui \
  -e OLLAMA_BASE_URL=http://localhost:11434 \
  ghcr.io/open-webui/open-webui:latest

# Truy cáº­p: http://localhost:3000
```

### 5ï¸âƒ£ Khá»Ÿi Äá»™ng Telegram Bot

```bash
# Activate virtual environment
source venv/bin/activate

# Cháº¡y bot
python3 tele_agent.py

# Output:
# INFO - Starting AI Agent Bot...
# INFO - Admin Chat ID: 123456789
# INFO - Model: qwen2.5:7b
```

## ğŸ“± Sá»­ Dá»¥ng Telegram Bot

### Lá»‡nh Há»‡ Thá»‘ng

| Lá»‡nh | MÃ´ táº£ |
|------|-------|
| `/start` | Khá»Ÿi Ä‘á»™ng bot, xem thÃ´ng tin |
| `/help` | HÆ°á»›ng dáº«n chi tiáº¿t |
| `/sys` | Kiá»ƒm tra RAM, CPU, Queue status |
| `/clear` | XÃ³a lá»‹ch sá»­ chat |

### TÆ°Æ¡ng TÃ¡c

1. **Chat bÃ¬nh thÆ°á»ng**: Gá»­i text, bot sáº½ tráº£ lá»i
2. **Gá»­i file**: Upload file .txt, bot sáº½ phÃ¢n tÃ­ch
3. **Queue notification**: Náº¿u AI Ä‘ang xá»­ lÃ½, sáº½ thÃ´ng bÃ¡o vá»‹ trÃ­ chá»

**VÃ­ dá»¥:**
```
Báº¡n: HÃ´m nay thá»i tiáº¿t tháº¿ nÃ o?
Bot: Äang Ä‘á»£i... (Vá»‹ trÃ­ trong hÃ ng: #1)
     (sau 30-60 giÃ¢y)
    Xin lá»—i, tÃ´i khÃ´ng cÃ³ thÃ´ng tin thá»i tiáº¿t real-time...

Báº¡n: /sys
Bot: ğŸ“Š SYSTEM STATUS REPORT
     Memory: Total: 8.0GB
             Used: 5.2GB (65%)
             Available: 2.8GB
     CPU: Cores: 4
          Usage: 35%
     AI Queue: Processing: Yes
                Queue: 0
```

## ğŸ“ Cáº¥u TrÃºc File

```
agent_mini/
â”œâ”€â”€ setup_system.sh          # Script cÃ i Ä‘áº·t tá»± Ä‘á»™ng
â”œâ”€â”€ tele_agent.py            # Telegram Bot + AI Engine
â”œâ”€â”€ .env.example             # Template cáº¥u hÃ¬nh
â”œâ”€â”€ .env                     # Cáº¥u hÃ¬nh thá»±c táº¿ (create tá»« .env.example)
â”œâ”€â”€ bot_agent.log            # Log file (tá»± Ä‘á»™ng táº¡o)
â””â”€â”€ data/
    â”œâ”€â”€ chat_history.db      # SQLite database
    â””â”€â”€ temp_files/          # ThÆ° má»¥c táº¡m file upload
```

## ğŸ”‘ Láº¥y Telegram Bot Token

1. Má»Ÿ Telegram, tÃ¬m `@BotFather`
2. Gá»­i `/newbot`
3. Äáº·t tÃªn bot (vÃ­ dá»¥: MyAIBot)
4. Láº¥y token (vÃ­ dá»¥: `123456:ABC-DEF1234ghIkl-zyx57W2v1u123ew11`)
5. Paste vÃ o `.env` file

## ğŸ‘¤ Láº¥y Chat ID

1. TÃ¬m `@userinfobot` trÃªn Telegram
2. Gá»­i `/start` 
3. Láº¥y ID vÃ  paste vÃ o `.env`

**Hoáº·c**: Gá»­i `/help` cho bot, sáº½ hiá»ƒn thá»‹ chat ID

## âš™ï¸ Optimization cho 8GB RAM

### Swap File
```bash
# Kiá»ƒm tra swap
free -h
swapon --show

# Script tá»± Ä‘á»™ng táº¡o 4GB swap file
```

### Ollama Optimization
- Model: qwen2.5:7b (~7GB)
- Threads: 4 (tá»‘i Æ°u 4-core CPU)
- Context window: 2048 tokens
- Memory cleanup: Auto gc.collect() every 5 responses

### Python Optimization
- Single worker queue (chá»‰ 1 AI request táº¡i má»™t lÃºc)
- History limit: 20 messages
- Message length limit: 4000 chars
- Async/await for non-blocking I/O

## ğŸ“Š Monitoring

### Real-time Monitor
```bash
# Terminal 1: Watch system resources
watch -n 1 'free -h && echo && ps aux | grep ollama'

# Terminal 2: Watch bot logs
tail -f bot_agent.log

# Terminal 3: Check Ollama
watch -n 1 'ollama list && echo && ollama ps'
```

### Database Queries
```bash
# Check conversation history
sqlite3 data/chat_history.db "SELECT * FROM conversations LIMIT 10;"

# Check user stats
sqlite3 data/chat_history.db "SELECT * FROM users;"

# Delete old messages (older than 30 days)
sqlite3 data/chat_history.db "
DELETE FROM conversations 
WHERE datetime(timestamp) < datetime('now', '-30 days');
"
```

## ğŸ› Troubleshooting

### "Permission denied" on setup_system.sh
```bash
chmod +x setup_system.sh
sudo ./setup_system.sh
```

### Ollama "Address already in use"
```bash
# Kill existing process
pkill -f ollama

# Or check what's using port 11434
lsof -i :11434
```

### ImportError: cannot import name 'ChatAction'
```bash
# Ensure correct python-telegram-bot version
source venv/bin/activate
pip install --upgrade python-telegram-bot==20.7
```

### Bot khÃ´ng respond
```bash
# 1. Check .env file
cat .env | grep TELEGRAM_API_TOKEN

# 2. Test Telegram connection
python3 -c "from telegram import Bot; print(Bot('YOUR_TOKEN').getMe())"

# 3. Check logs
tail -f bot_agent.log
```

### Out of Memory (OOM)
```bash
# Check memory usage
ps aux --sort=-%mem | head -10

# Check swap
free -h

# Increase swap if needed
sudo fallocate -l 4G /swapfile2
sudo mkswap /swapfile2
sudo swapon /swapfile2
```

### Slow Response
```bash
# 1. Check CPU usage
top -b -n 1 | head -10

# 2. Check if queue is building up
# Use /sys command on Telegram

# 3. Reduce context window in code
# Edit tele_agent.py line: 'num_ctx': 1024  (from 2048)
```

## ğŸ”§ Advanced Configuration

### Thay Ä‘á»•i Model
```bash
# Edit .env
OLLAMA_MODEL=qwen2.5:14b  # Cháº­m hÆ¡n, chÃ­nh xÃ¡c hÆ¡n
# hoáº·c
OLLAMA_MODEL=mistral  # Nhanh hÆ¡n, nhÆ°ng kÃ©m tiáº¿ng Viá»‡t

# Pull model
ollama pull qwen2.5:14b

# Restart bot
python3 tele_agent.py
```

### Äiá»u chá»‰nh Queue
```python
# tele_agent.py - line 83
QUEUE_CHECK_INTERVAL = 1  # Kiá»ƒm tra thÆ°á»ng xuyÃªn hÆ¡n
MAX_WORKERS = 1  # Giá»¯ = 1 Ä‘á»ƒ tá»‘i Æ°u

# Hoáº·c tÄƒng Ä‘á»ƒ xá»­ lÃ½ nhiá»u request
MAX_WORKERS = 2  # NhÆ°ng cáº§n 16GB RAM
```

### Custom System Prompt
```python
# tele_agent.py - AIAgent.generate_response() method
system_prompt = """Báº¡n lÃ  má»™t chuyÃªn gia vá» láº­p trÃ¬nh Python...
..."""
```

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

- [Ollama Documentation](https://ollama.ai)
- [python-telegram-bot](https://python-telegram-bot.readthedocs.io)
- [Open WebUI](https://github.com/open-webui/open-webui)
- [qwen2.5 Model Info](https://huggingface.co/Qwen/Qwen2.5-7B)

## ğŸ“ License

MIT License - Tá»± do sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch cÃ¡ nhÃ¢n

## ğŸ¤ Support

Gáº·p váº¥n Ä‘á»? Kiá»ƒm tra:
1. Log file: `bot_agent.log`
2. System resources: `/sys` command
3. Ollama status: `ollama ps`
4. Python version: `python3 --version` (cáº§n 3.10+)

---

**Enjoy your local AI Agent! ğŸš€**
