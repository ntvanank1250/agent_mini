# ğŸ¤– AI Agent Telegram Bot - Há»‡ Thá»‘ng AI CÃ¡

 NhÃ¢n Cháº¡y Local

Há»‡ thá»‘ng AI Agent cÃ¡ nhÃ¢n cháº¡y hoÃ n toÃ n trÃªn mÃ¡y local (Fedora/Ubuntu) vá»›i Telegram Bot + Ollama AI Engine. Tá»‘i Æ°u cho mÃ¡y 8-16GB RAM.

## âœ¨ TÃ­nh NÄƒng Ná»•i Báº­t

- âœ… **Ollama AI Integration**: Model qwen2.5:7b (4.7GB) - tá»‘i Æ°u tiáº¿ng Viá»‡t
- âœ… **Telegram Bot**: TrÃ² chuyá»‡n AI qua Telegram Messenger  
- âœ… **LÆ°u Trá»¯ Há»™i Thoáº¡i**: SQLite database vá»›i lá»‹ch sá»­ chat
- âœ… **Há»‡ Thá»‘ng Queue**: Xá»­ lÃ½ tuáº§n tá»± requests (tá»‘i Æ°u RAM)
- âœ… **PhÃ¢n TÃ­ch File**: Äá»c vÃ  tÃ³m táº¯t file .txt
- âœ… **GiÃ¡m SÃ¡t Há»‡ Thá»‘ng**: Kiá»ƒm tra RAM/CPU/Queue real-time
- âœ… **Quáº£n LÃ½ Dá»… DÃ ng**: Script tá»± Ä‘á»™ng start/stop/monitor
- âœ… **Báº£o Máº­t**: Chá»‰ admin Ä‘Æ°á»£c sá»­ dá»¥ng bot

## ğŸ› ï¸ YÃªu Cáº§u Há»‡ Thá»‘ng

```yaml
Hardware:
  CPU: 4-12 cores (khuyáº¿n nghá»‹ 8+)
  RAM: 8GB tá»‘i thiá»ƒu, 16GB khuyáº¿n nghá»‹
  Disk: 20GB trá»‘ng (cho model + dá»¯ liá»‡u)
  Network: Káº¿t ná»‘i internet á»•n Ä‘á»‹nh

Há»‡ Äiá»u HÃ nh:
  - Fedora Linux (Ä‘Ã£ test)
  - Ubuntu 20.04+ 
  - Debian-based distros
  - CentOS/RHEL 8+

Pháº§n Má»m:
  - Python 3.10+
  - Bash shell
  - curl, git
  - Ollama (script tá»± Ä‘á»™ng cÃ i)
```

## ğŸš€ CÃ i Äáº·t Nhanh

### BÆ°á»›c 1: Clone Project

```bash
cd ~
git clone <repository-url> agent_mini
cd agent_mini
```

### BÆ°á»›c 2: Cáº¥u HÃ¬nh MÃ´i TrÆ°á»ng

```bash
# Táº¡o file cáº¥u hÃ¬nh tá»« template
cp .env.example .env

# Chá»‰nh sá»­a thÃ´ng tin
nano .env
```

**Ná»™i dung `.env` cáº§n Ä‘iá»n:**

```env
# Token tá»« @BotFather trÃªn Telegram
TELEGRAM_API_TOKEN=123456789:ABCdefGHIjklMNOpqrsTUVwxyz

# Chat ID cá»§a báº¡n (tÃ¬m qua @userinfobot)
ADMIN_CHAT_ID=123456789

# Cáº¥u hÃ¬nh Ollama (máº·c Ä‘á»‹nh OK)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b

# Há»‡ thá»‘ng (giá»¯ nguyÃªn)
MAX_WORKERS=1
QUEUE_CHECK_INTERVAL=2
```

### BÆ°á»›c 3: Cháº¡y Script CÃ i Äáº·t

```bash
# Cáº¥p quyá»n thá»±c thi
chmod +x setup_system.sh

# Cháº¡y script (cáº§n sudo)
sudo ./setup_system.sh
```

**Script sáº½ tá»± Ä‘á»™ng:**
- âœ“ Táº¡o swap file 4GB (náº¿u chÆ°a cÃ³)
- âœ“ CÃ i Ä‘áº·t Ollama AI engine
- âœ“ Pull model qwen2.5:7b (~4.7GB, máº¥t 10-20 phÃºt)
- âœ“ Táº¡o Python virtual environment
- âœ“ CÃ i Ä‘áº·t táº¥t cáº£ dependencies
- âœ“ Kiá»ƒm tra vÃ  xÃ¡c nháº­n cÃ i Ä‘áº·t thÃ nh cÃ´ng

### BÆ°á»›c 4: Khá»Ÿi Äá»™ng Bot

```bash
# CÃ¡ch 1: Sá»­ dá»¥ng script quáº£n lÃ½ (khuyáº¿n nghá»‹)
./manage.sh start

# CÃ¡ch 2: Khá»Ÿi Ä‘á»™ng thá»§ cÃ´ng
source venv/bin/activate
python3 tele_agent.py
```

**Kiá»ƒm tra tráº¡ng thÃ¡i:**

```bash
./manage.sh status
```

## ğŸ“± Sá»­ Dá»¥ng Bot

### CÃ¡c Lá»‡nh Telegram

| Lá»‡nh | Chá»©c NÄƒng |
|------|-----------|
| `/start` | Khá»Ÿi Ä‘á»™ng bot, xem hÆ°á»›ng dáº«n |
| `/help` | Hiá»ƒn thá»‹ trá»£ giÃºp chi tiáº¿t |
| `/sys` | Kiá»ƒm tra RAM, CPU, queue status |
| `/clear` | XÃ³a lá»‹ch sá»­ há»™i thoáº¡i |

### VÃ­ Dá»¥ Sá»­ Dá»¥ng

**Chat ThÃ´ng ThÆ°á»ng:**
```
Báº¡n: xin chÃ o, báº¡n lÃ  ai?
Bot: Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cháº¡y local trÃªn mÃ¡y cá»§a báº¡n...
```

**Kiá»ƒm Tra Há»‡ Thá»‘ng:**
```
Báº¡n: /sys
Bot: ğŸ“Š SYSTEM STATUS REPORT
     Memory: Total 15.2GB, Used 11.0GB (72%)
     CPU: 12 cores, Usage 45%
     AI Queue: Processing No, Queue 0
     Model: qwen2.5:7b, Threads: 8
```

## ğŸ”§ Quáº£n LÃ½ Há»‡ Thá»‘ng

### Script `manage.sh`

```bash
./manage.sh start          # Khá»Ÿi Ä‘á»™ng Ollama + Bot
./manage.sh stop           # Dá»«ng dá»‹ch vá»¥
./manage.sh restart        # Khá»Ÿi Ä‘á»™ng láº¡i
./manage.sh status         # Kiá»ƒm tra tráº¡ng thÃ¡i
./manage.sh logs-live      # Xem logs real-time
./manage.sh db-backup      # Backup database
./manage.sh db-cleanup     # Dá»n dáº¹p database cÅ©
```

### CÃ¡c Script Phá»¥ Trá»£

```bash
./start.sh        # Khá»Ÿi Ä‘á»™ng nhanh
./stop.sh         # Dá»«ng nhanh
./status.sh       # Xem tráº¡ng thÃ¡i
./logs.sh         # Hiá»ƒn thá»‹ logs
./monitor.sh      # GiÃ¡m sÃ¡t resources
./quick-install.sh # CÃ i Ä‘áº·t + start tá»± Ä‘á»™ng
```

## ğŸ“ Cáº¥u TrÃºc Project

```
agent_mini/
â”œâ”€â”€ tele_agent.py              # Bot chÃ­nh (700 dÃ²ng)
â”œâ”€â”€ setup_system.sh            # Script cÃ i Ä‘áº·t tá»± Ä‘á»™ng
â”œâ”€â”€ manage.sh                  # Quáº£n lÃ½ há»‡ thá»‘ng
â”œâ”€â”€ .env                       # Cáº¥u hÃ¬nh (táº¡o tá»« .env.example)
â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚
â”œâ”€â”€ Scripts:
â”‚   â”œâ”€â”€ start.sh, stop.sh, status.sh
â”‚   â”œâ”€â”€ logs.sh, monitor.sh
â”‚   â””â”€â”€ quick-install.sh
â”‚
â”œâ”€â”€ Data:
â”‚   â”œâ”€â”€ bot_agent.log          # Log file
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ chat_history.db    # SQLite
â”‚       â””â”€â”€ temp_files/        # Temp folder
â”‚
â””â”€â”€ Config:
    â”œâ”€â”€ .env.example           # Template
    â”œâ”€â”€ docker-compose.yml     # Web UI
    â””â”€â”€ tele_agent.service     # Systemd
```

## âš™ï¸ Tá»‘i Æ¯u ÄÃ£ Ãp Dá»¥ng

**Ollama:**
- Threads: 8 (táº­n dá»¥ng CPU)
- Context: 4096 tokens
- Temperature: 0.7, Top-p: 0.9

**Bot:**
- Lock-based queue (1 worker)
- History: 20 messages
- GC: má»—i 5 responses
- Max message: 4000 chars

**ÄÃ£ Fix:**
- âœ… 409 Conflict (kill duplicate instances)
- âœ… Chat.action error (thay send_action)  
- âœ… Coroutine split (normalize responses)
- âœ… Queue hang (lock-based processing)
- âœ… Slow response (8 threads + 4K context)
- âœ… Mixed language (Viá»‡t-Trung prompt)

## ğŸ› Xá»­ LÃ½ Lá»—i

### Bot KhÃ´ng Pháº£n Há»“i

```bash
# Kill duplicate bots
pkill -f tele_agent.py

# Restart
./manage.sh start
```

### Ollama Lá»—i

```bash
# Kiá»ƒm tra
ollama list
ollama ps

# Restart
ollama serve &
```

### Bot Cháº­m

```bash
# Xem logs
tail -50 bot_agent.log

# Kiá»ƒm tra RAM
free -h

# Restart
./manage.sh restart
```

## ğŸ”‘ Láº¥y Token & Chat ID

### Token Telegram

1. Má»Ÿ @BotFather
2. `/newbot` â†’ Ä‘áº·t tÃªn/username
3. Copy token vÃ o `.env`

### Chat ID

1. Má»Ÿ @userinfobot  
2. `/start` â†’ láº¥y ID
3. Copy vÃ o `.env`

## ğŸ“Š GiÃ¡m SÃ¡t

```bash
# Logs real-time
tail -f bot_agent.log

# Database
sqlite3 data/chat_history.db "SELECT * FROM conversations LIMIT 10;"

# Resources
./monitor.sh
```

## ğŸš€ NÃ¢ng Cao

### Cháº¡y Service

```bash
sudo cp tele_agent.service /etc/systemd/system/
sudo systemctl enable tele_agent
sudo systemctl start tele_agent
```

### Thay Model

```bash
ollama pull mistral
nano .env  # OLLAMA_MODEL=mistral
./manage.sh restart
```

### TÃ¹y Chá»‰nh Prompt

Sá»­a `tele_agent.py` dÃ²ng ~360:
```python
system_prompt = """Báº¡n lÃ  chuyÃªn gia Python..."""
```

## ğŸ“š TÃ i Liá»‡u

- [Ollama Docs](https://ollama.ai/docs)
- [python-telegram-bot](https://docs.python-telegram-bot.org)
- [Qwen2.5 Model](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)

## ğŸ¤ Há»— Trá»£

**Checklist Debug:**
- [ ] Files `.env` Ä‘Ãºng token/chat ID?
- [ ] Ollama running? (`pgrep ollama`)
- [ ] Bot running? (`pgrep tele_agent`)
- [ ] Venv activated?
- [ ] Dependencies installed?
- [ ] No duplicate bots?

## ğŸ“ License

MIT License - Free for personal/commercial use

---

**Táº­n hÆ°á»Ÿng AI cá»§a riÃªng báº¡n! ğŸš€**

Made with â¤ï¸ for Vietnamese AI Community
